{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation, TruncatedSVD, NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords, words\n",
    "import re\n",
    "import string\n",
    "\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20805</td>\n",
       "      <td>Trump is USA's antique hero. Clinton will be n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump is USA's antique hero. Clinton will be n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20806</td>\n",
       "      <td>Pelosi Calls for FBI Investigation to Find Out...</td>\n",
       "      <td>Pam Key</td>\n",
       "      <td>Sunday on NBC’s “Meet the Press,” House Minori...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20807</td>\n",
       "      <td>Weekly Featured Profile – Randy Shannon</td>\n",
       "      <td>Trevor Loudon</td>\n",
       "      <td>You are here: Home / *Articles of the Bound* /...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20808</td>\n",
       "      <td>Urban Population Booms Will Make Climate Chang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban Population Booms Will Make Climate Chang...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cognitive dissident</td>\n",
       "      <td>don't we have the receipt?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "5  20805  Trump is USA's antique hero. Clinton will be n...   \n",
       "6  20806  Pelosi Calls for FBI Investigation to Find Out...   \n",
       "7  20807            Weekly Featured Profile – Randy Shannon   \n",
       "8  20808  Urban Population Booms Will Make Climate Chang...   \n",
       "9  20809                                                NaN   \n",
       "\n",
       "                    author                                               text  \\\n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...   \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...   \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...   \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...   \n",
       "5                      NaN  Trump is USA's antique hero. Clinton will be n...   \n",
       "6                  Pam Key  Sunday on NBC’s “Meet the Press,” House Minori...   \n",
       "7            Trevor Loudon  You are here: Home / *Articles of the Bound* /...   \n",
       "8                      NaN  Urban Population Booms Will Make Climate Chang...   \n",
       "9      cognitive dissident                         don't we have the receipt?   \n",
       "\n",
       "   label  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "5    NaN  \n",
       "6    NaN  \n",
       "7    NaN  \n",
       "8    NaN  \n",
       "9    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Datasets\\Train.csv')\n",
    "test_df = pd.read_csv('Datasets\\Test.csv')\n",
    "df = pd.merge(test_df, train_df, on=('id','title', 'author', 'text'), how='outer', suffixes=('_', '_'))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26000 entries, 0 to 25999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      26000 non-null  int64  \n",
      " 1   title   25320 non-null  object \n",
      " 2   author  23540 non-null  object \n",
      " 3   text    25954 non-null  object \n",
      " 4   label   20800 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(news_articles):\n",
    "    #We will begin by Lower case\n",
    "    news_articles = news_articles.lower()\n",
    "\n",
    "    #And then we will remove the numbers from the text.\n",
    "    news_articles = \"\".join([i for i in news_articles if not i.isdigit()])\n",
    "\n",
    "    #We will then remove the punctuations\n",
    "    news_articles = \"\".join(\n",
    "        [i for i in news_articles if i not in string.punctuation])\n",
    "\n",
    "    #We will then breakdown the text sentences into smaller portions.\n",
    "    tokens = word_tokenize(news_articles)\n",
    "\n",
    "    #Removing stop words and then we will begin the Lemmatization process\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    news_articless = [\n",
    "        lemmatizer.lemmatize(w) for w in tokens if w not in stop_words\n",
    "    ]\n",
    "\n",
    "    return news_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rayni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5200     1.0\n",
       "5201     0.0\n",
       "5202     1.0\n",
       "5203     1.0\n",
       "5204     1.0\n",
       "        ... \n",
       "25995    0.0\n",
       "25996    0.0\n",
       "25997    0.0\n",
       "25998    1.0\n",
       "25999    1.0\n",
       "Name: label, Length: 18285, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "#We then create a function to remove the stopwords in our text.\n",
    "def remove_stopwords(text):\n",
    "    text_Array = text.split(' ')\n",
    "    remove_words = \" \".join([i for i in text_Array if i not in stop_words])\n",
    "    return remove_words\n",
    "\n",
    "\n",
    "#And here we will apply the remove_stopwords function. This will remove the stopwords from our dataset's text\n",
    "df['content'] = df['title'] + \" \" + df['author']\n",
    "df['content'] = df['content'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman Campus - Bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why Truth Might Get You Fired Consortiumnews.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iranian woman jailed fictional unpublished sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump He Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>9</td>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A Back-Channel Plan Ukraine Russia, Courtesy T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>10</td>\n",
       "      <td>Obama’s Organizing for Action Partners with So...</td>\n",
       "      <td>Aaron Klein</td>\n",
       "      <td>Organizing for Action, the activist group that...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Obama’s Organizing Action Partners Soros-Linke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>11</td>\n",
       "      <td>BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...</td>\n",
       "      <td>Chris Tomlinson</td>\n",
       "      <td>The BBC produced spoof on the “Real Housewives...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBC Comedy Sketch \"Real Housewives ISIS\" Cause...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "5200   0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "5201   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "5202   2                  Why the Truth Might Get You Fired   \n",
       "5203   3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "5204   4  Iranian woman jailed for fictional unpublished...   \n",
       "5205   5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "5207   7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "5209   9  A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "5210  10  Obama’s Organizing for Action Partners with So...   \n",
       "5211  11  BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...   \n",
       "\n",
       "                            author  \\\n",
       "5200                 Darrell Lucus   \n",
       "5201               Daniel J. Flynn   \n",
       "5202            Consortiumnews.com   \n",
       "5203               Jessica Purkiss   \n",
       "5204                Howard Portnoy   \n",
       "5205               Daniel Nussbaum   \n",
       "5207               Alissa J. Rubin   \n",
       "5209  Megan Twohey and Scott Shane   \n",
       "5210                   Aaron Klein   \n",
       "5211               Chris Tomlinson   \n",
       "\n",
       "                                                   text  label  \\\n",
       "5200  House Dem Aide: We Didn’t Even See Comey’s Let...    1.0   \n",
       "5201  Ever get the feeling your life circles the rou...    0.0   \n",
       "5202  Why the Truth Might Get You Fired October 29, ...    1.0   \n",
       "5203  Videos 15 Civilians Killed In Single US Airstr...    1.0   \n",
       "5204  Print \\nAn Iranian woman has been sentenced to...    1.0   \n",
       "5205  In these trying times, Jackie Mason is the Voi...    0.0   \n",
       "5207  PARIS  —   France chose an idealistic, traditi...    0.0   \n",
       "5209  A week before Michael T. Flynn resigned as nat...    0.0   \n",
       "5210  Organizing for Action, the activist group that...    0.0   \n",
       "5211  The BBC produced spoof on the “Real Housewives...    0.0   \n",
       "\n",
       "                                                content  \n",
       "5200  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "5201  FLYNN: Hillary Clinton, Big Woman Campus - Bre...  \n",
       "5202   Why Truth Might Get You Fired Consortiumnews.com  \n",
       "5203  15 Civilians Killed In Single US Airstrike Hav...  \n",
       "5204  Iranian woman jailed fictional unpublished sto...  \n",
       "5205  Jackie Mason: Hollywood Would Love Trump He Bo...  \n",
       "5207  Benoît Hamon Wins French Socialist Party’s Pre...  \n",
       "5209  A Back-Channel Plan Ukraine Russia, Courtesy T...  \n",
       "5210  Obama’s Organizing Action Partners Soros-Linke...  \n",
       "5211  BBC Comedy Sketch \"Real Housewives ISIS\" Cause...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "counts = count_vectorizer.fit_transform(df['content'].values)\n",
    "tfidf = transformer.fit_transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df['label'].values\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf,\n",
    "                                                    targets,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=49)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report, roc_curve\n",
    "\n",
    "\n",
    "def train(model, model_name):\n",
    "    model.fit(x_train, y_train)\n",
    "    print(\n",
    "        f\"Training accuracy of {model_name} is {model.score(x_train,y_train)}\")\n",
    "    print(f\"testing accuracy of {model_name} is {model.score(x_test,y_test)}\")\n",
    "\n",
    "\n",
    "def conf_matrix(model):\n",
    "    ConfusionMatrixDisplay.from_estimator(model, x_test, y_test)\n",
    "\n",
    "\n",
    "def class_report(model):\n",
    "    print(classification_report(y_test, model.predict(x_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of SVC is 0.9998632759092152\n",
      "testing accuracy of SVC is 0.9860541427399507\n",
      "Training accuracy of Linear Regression is 0.9999999999999136\n",
      "testing accuracy of Linear Regression is 0.9230258182115304\n",
      "Fitting 5 folds for each of 33 candidates, totalling 165 fits\n",
      "Training accuracy of Random Forest Classifier is 0.9872846595570139\n",
      "testing accuracy of Random Forest Classifier is 0.9685534591194969\n",
      "Training accuracy of Decision Tree Classifier is 0.9976073284112661\n",
      "testing accuracy of Decision Tree Classifier is 0.9945310363686082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "model_svc = SVC()\n",
    "model_lr = LinearRegression()\n",
    "model_rfc = RandomForestClassifier(random_state=42)\n",
    "params = {\"n_estimators\": range(50, 125, 25), \"max_depth\": range(60, 81, 2)}\n",
    "rfc_model = GridSearchCV(model_rfc, param_grid=params, cv=5, n_jobs=-1, verbose=1)\n",
    "model_dtc = DecisionTreeClassifier(max_depth=58, random_state=42)\n",
    "model_dtc.fit(x_train,y_train)\n",
    "\n",
    "train(model_svc, 'SVC')\n",
    "train(model_lr, 'Linear Regression')\n",
    "train(rfc_model, 'Random Forest Classifier')\n",
    "train(model_dtc, 'Decision Tree Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      2126\n",
      "         1.0       0.97      1.00      0.98      1531\n",
      "\n",
      "    accuracy                           0.99      3657\n",
      "   macro avg       0.98      0.99      0.99      3657\n",
      "weighted avg       0.99      0.99      0.99      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(model_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97      2126\n",
      "         1.0       0.93      1.00      0.96      1531\n",
      "\n",
      "    accuracy                           0.97      3657\n",
      "   macro avg       0.97      0.97      0.97      3657\n",
      "weighted avg       0.97      0.97      0.97      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(rfc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      2126\n",
      "         1.0       0.99      1.00      0.99      1531\n",
      "\n",
      "    accuracy                           0.99      3657\n",
      "   macro avg       0.99      0.99      0.99      3657\n",
      "weighted avg       0.99      0.99      0.99      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(model_dtc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
